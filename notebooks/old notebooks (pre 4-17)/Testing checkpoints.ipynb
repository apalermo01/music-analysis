{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Testing checkpoints.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNfOpgVmon3W","executionInfo":{"status":"ok","timestamp":1619484503242,"user_tz":240,"elapsed":4433,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"43408f95-4047-433b-80d8-7361ea7f21ef"},"source":["! pip install torch-summary"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torch-summary\n","  Downloading https://files.pythonhosted.org/packages/ca/db/93d18c84f73b214acfa4d18051d6f4263eee3e044c408928e8abe941a22c/torch_summary-1.4.5-py3-none-any.whl\n","Installing collected packages: torch-summary\n","Successfully installed torch-summary-1.4.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zxqWMNgUDB4X","executionInfo":{"status":"ok","timestamp":1619484508144,"user_tz":240,"elapsed":9330,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import pandas as pd\n","import json\n","from torchsummary import summary\n","import time\n","# from sklearn.preprocessing import OneHotEncoder\n","# from sklearn.preprocessing import LabelBinarizer\n","from sklearn.preprocessing import LabelEncoder\n","import librosa.display\n","\n","IRMAS_PATH = \"/content/drive/MyDrive/ITCS 5156 project/IRMAS dataset/IRMAS-TrainingData/\"\n","JSON_PATH = \"/content/drive/MyDrive/ITCS 5156 project/IRMAS dataset/json_files/\"\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/ITCS 5156 project/trained_models/\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWVv6fbeDake","executionInfo":{"status":"ok","timestamp":1619484529971,"user_tz":240,"elapsed":29997,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"0f264755-604b-4235-98aa-2378791b7154"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DQSOy2W5Db0-"},"source":["# Ensure that saved checkpoint files are loaded properly"]},{"cell_type":"code","metadata":{"id":"fn7sOurlDxOt"},"source":["checkpoint_name = \"CNN tests 4-19/CNN_1_layers_channel_0.pt\"\n","\n","model_dict = torch.load(CHECKPOINT_PATH + checkpoint_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6OManenEAaV","executionInfo":{"status":"ok","timestamp":1618880242765,"user_tz":240,"elapsed":402,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"d8a311d4-45c2-408d-8a29-18753d3dbe3d"},"source":["model_dict.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['filename', 'epochs', 'model_id', 'model_state_dict', 'avg_train_loss_hist', 'std_train_loss_hist', 'avg_val_loss_hist', 'std_val_loss_hist', 'train_acc_hist', 'val_acc_hist', 'dataset_info', 'notes', 'summary', 'experiment_params'])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8djqI0peECZM","executionInfo":{"status":"ok","timestamp":1618880247976,"user_tz":240,"elapsed":290,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"32bfa635-b4a5-4f5f-e814-eb0482265324"},"source":["print(model_dict['summary'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","├─ConvBlock: 1-1                         [-1, 8, 5, 257]           --\n","|    └─Sequential: 2-1                   [-1, 8, 5, 257]           --\n","|    |    └─Conv2d: 3-1                  [-1, 8, 11, 515]          80\n","|    |    └─ReLU: 3-2                    [-1, 8, 11, 515]          --\n","|    |    └─MaxPool2d: 3-3               [-1, 8, 5, 257]           --\n","|    |    └─BatchNorm2d: 3-4             [-1, 8, 5, 257]           16\n","├─LinearBlock: 1-2                       [-1, 128]                 --\n","|    └─Sequential: 2-2                   [-1, 128]                 --\n","|    |    └─Linear: 3-5                  [-1, 128]                 1,315,968\n","|    |    └─ReLU: 3-6                    [-1, 128]                 --\n","|    |    └─BatchNorm1d: 3-7             [-1, 128]                 256\n","|    |    └─Dropout: 3-8                 [-1, 128]                 --\n","├─LinearBlock: 1-3                       [-1, 64]                  --\n","|    └─Sequential: 2-3                   [-1, 64]                  --\n","|    |    └─Linear: 3-9                  [-1, 64]                  8,256\n","|    |    └─ReLU: 3-10                   [-1, 64]                  --\n","|    |    └─BatchNorm1d: 3-11            [-1, 64]                  128\n","|    |    └─Dropout: 3-12                [-1, 64]                  --\n","├─HeadBlock: 1-4                         [-1, 11]                  --\n","|    └─Sequential: 2-4                   [-1, 11]                  --\n","|    |    └─Linear: 3-13                 [-1, 11]                  715\n","|    |    └─Softmax: 3-14                [-1, 11]                  --\n","==========================================================================================\n","Total params: 1,325,419\n","Trainable params: 1,325,419\n","Non-trainable params: 0\n","Total mult-adds (M): 4.38\n","==========================================================================================\n","Input size (MB): 0.03\n","Forward/backward pass size (MB): 0.43\n","Params size (MB): 5.06\n","Estimated Total Size (MB): 5.51\n","==========================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRAmZnFVEGT_","executionInfo":{"status":"ok","timestamp":1618880299499,"user_tz":240,"elapsed":280,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"2c5d86c4-14bf-4b10-ddfd-deb4b218d025"},"source":["model_dict['experiment_params']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'channels': [8], 'num_conv_layers': 1}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"RGZrXr2_zPBG"},"source":["# Update 4/26: load a batch of models"]},{"cell_type":"markdown","metadata":{"id":"jt7DgriQzfib"},"source":["# Define architectures"]},{"cell_type":"code","metadata":{"id":"-gt-z3DKrHd7","executionInfo":{"status":"ok","timestamp":1619484650020,"user_tz":240,"elapsed":674,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["class ConvBlock(nn.Module):\n","  \"\"\"Convolutional block with conv2d, linear activation, max pooling, and batch norm\n","  \"\"\"\n","  def __init__(self, in_channels, out_channels, conv_kernel_size=3,\n","               conv_stride=1, conv_padding=0,\n","               inc_pool=True, pool_kernel_size=2, pool_stride=2):\n","    super(ConvBlock, self).__init__()\n","    if inc_pool:\n","      self.conv_block = nn.Sequential(\n","          nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n","                    kernel_size=conv_kernel_size, stride=conv_stride,\n","                    padding=conv_padding),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=pool_kernel_size, stride=pool_stride),\n","          nn.BatchNorm2d(num_features=out_channels)\n","      ) \n","    else:\n","      self.conv_block = nn.Sequential(\n","          nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n","                    kernel_size=conv_kernel_size, stride=conv_stride,\n","                    padding=conv_padding),\n","          nn.ReLU(),\n","          nn.BatchNorm2d(num_features=out_channels)\n","      ) \n","\n","  def forward(self, x):\n","    x = self.conv_block(x)\n","    return x\n","\n","class LinearBlock(nn.Module):\n","  \"\"\"Linear block with dense layer, relu, batch norm, then dropout\n","  \"\"\"\n","\n","  def __init__(self, in_features, out_features, dropout_prob=0):\n","    super(LinearBlock, self).__init__()\n","    self.linear_block = nn.Sequential(\n","        nn.Linear(in_features=in_features, out_features=out_features),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(num_features=out_features),\n","        nn.Dropout(p=dropout_prob)\n","    )\n","\n","  def forward(self, x):\n","    x = self.linear_block(x)\n","    return x\n","\n","class HeadBlock(nn.Module):\n","  \"\"\"Linear block with softmax output\"\"\"\n","  def __init__(self, in_features):\n","    super(HeadBlock, self).__init__()\n","    self.head_block = nn.Sequential(\n","        nn.Linear(in_features=in_features, out_features=11),\n","        #nn.Softmax()\n","    )\n","\n","  def forward(self, x):\n","    x = self.head_block(x)\n","    return x\n","\n","class Conv1Layer(nn.Module):\n","\n","  def __init__(self, single_sample, channels=[8],\n","               conv_kernel_sizes=[3],\n","               conv_strides=[1],\n","               conv_paddings=[0],\n","               pool_masks=[True],\n","               pool_kernel_sizes=[2],\n","               pool_strides=[2],\n","               linear_features=[128, 64],\n","               dropout_probs=[0, 0]):\n","\n","    super(Conv1Layer, self).__init__()\n","\n","    # convolutional blocks\n","    self.conv1 = ConvBlock(in_channels=1, out_channels=channels[0],\n","                           conv_kernel_size=conv_kernel_sizes[0],\n","                           conv_stride=conv_strides[0],\n","                           conv_padding=conv_paddings[0],\n","                           inc_pool=pool_masks[0],\n","                           pool_kernel_size=pool_kernel_sizes[0],\n","                           pool_stride=pool_strides[0])\n","  \n","    # run a single sample through the convolutional block to get output size\n","    # https://discuss.pytorch.org/t/convolution-and-pooling-layers-need-a-method-to-calculate-output-size/21895\n","    sample_output1 = self.conv1(torch.from_numpy(\n","        single_sample[np.newaxis,...].astype(np.float32)))\n","  \n","    sample_flattened = sample_output1.flatten(start_dim=1)\n"," \n","    # linear blocks\n","    self.linear1 = LinearBlock(in_features=(sample_flattened.shape[1]),\n","                                            out_features=(linear_features[0]),\n","                                            dropout_prob=dropout_probs[0])\n","    self.linear2 = LinearBlock(in_features=(linear_features[0]),\n","                                            out_features=(linear_features[1]),\n","                                            dropout_prob=dropout_probs[1])\n","    self.head = HeadBlock(in_features=(linear_features[1]))\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = x.flatten(start_dim=1)\n","    x = self.linear1(x)\n","    x = self.linear2(x)\n","    x = self.head(x)\n","    return x\n","\n","class Conv3Layer(nn.Module):\n","  def __init__(self, single_sample, channels=[8, 16, 32],\n","               conv_kernel_sizes=[3, 3, 3],\n","               conv_strides=[1, 1, 1],\n","               conv_paddings=[0, 0, 1,],\n","               pool_masks=[True, False, False],\n","               pool_kernel_sizes=[2, 2, 2],\n","               pool_strides=[2, 2, 2],\n","               linear_features=[128, 64],\n","               dropout_probs=[0, 0]):\n","    super(Conv3Layer, self).__init__()\n","\n","    self.conv1 = ConvBlock(in_channels=1, out_channels=channels[0],\n","                           conv_kernel_size=conv_kernel_sizes[0],\n","                           conv_stride=conv_strides[0],\n","                           conv_padding=conv_paddings[0],\n","                           inc_pool=pool_masks[0],\n","                           pool_kernel_size=pool_kernel_sizes[0],\n","                           pool_stride=pool_strides[0])\n","    \n","    self.conv2 = ConvBlock(in_channels=channels[0], out_channels=channels[1],\n","                           conv_kernel_size=conv_kernel_sizes[1],\n","                           conv_stride=conv_strides[1],\n","                           conv_padding=conv_paddings[1],\n","                           inc_pool=pool_masks[1],\n","                           pool_kernel_size=pool_kernel_sizes[1],\n","                           pool_stride=pool_strides[1])\n","\n","    self.conv3 = ConvBlock(in_channels=channels[1], out_channels=channels[2],\n","                           conv_kernel_size=conv_kernel_sizes[2],\n","                           conv_stride=conv_strides[2],\n","                           conv_padding=conv_paddings[2],\n","                           inc_pool=pool_masks[2],\n","                           pool_kernel_size=pool_kernel_sizes[2],\n","                           pool_stride=pool_strides[2])\n","    \n","    # calculate size for linear layers\n","    sample_output1 = self.conv1(torch.from_numpy(\n","        single_sample[np.newaxis,...].astype(np.float32)))\n","    sample_output2 = self.conv2(sample_output1)\n","    sample_output3 = self.conv3(sample_output2)\n","    sample_flattened = sample_output3.flatten(start_dim=1)\n","\n","    # linear blocks\n","    self.linear1 = LinearBlock(in_features=(sample_flattened.shape[1]),\n","                                            out_features=(linear_features[0]),\n","                                            dropout_prob=dropout_probs[0])\n","    self.linear2 = LinearBlock(in_features=(linear_features[0]),\n","                                            out_features=(linear_features[1]),\n","                                            dropout_prob=dropout_probs[1])\n","    self.head = HeadBlock(in_features=(linear_features[1]))\n","  \n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.conv2(x)\n","    x = self.conv3(x)\n","    x = x.flatten(start_dim=1)\n","    x = self.linear1(x)\n","    x = self.linear2(x)\n","    x = self.head(x)\n","    return x\n","\n","class Conv5Layer(nn.Module):\n","  def __init__(self, single_sample, channels= [8, 8, 32, 32, 64],\n","               conv_kernel_sizes=[3, 3, 3, 3, 3],\n","               conv_strides=[1, 1, 1, 1, 1],\n","               conv_paddings=[0, 0, 1, 1, 1],\n","               pool_masks=[True, False, False, False, False],\n","               pool_kernel_sizes=[2, 2, 2, 2, 2],\n","               pool_strides=[2, 2, 2, 2, 2],\n","               linear_features=[128, 64],\n","               dropout_probs=[0, 0]):\n","    super(Conv5Layer, self).__init__()\n","\n","    # convolutional layers\n","    self.conv1 = ConvBlock(in_channels=1, out_channels=channels[0],\n","                           conv_kernel_size=conv_kernel_sizes[0],\n","                           conv_stride=conv_strides[0],\n","                           conv_padding=conv_paddings[0],\n","                           inc_pool=pool_masks[0],\n","                           pool_kernel_size=pool_kernel_sizes[0],\n","                           pool_stride=pool_strides[0])\n","    \n","    self.conv2 = ConvBlock(in_channels=channels[0], out_channels=channels[1],\n","                           conv_kernel_size=conv_kernel_sizes[1],\n","                           conv_stride=conv_strides[1],\n","                           conv_padding=conv_paddings[1],\n","                           inc_pool=pool_masks[1],\n","                           pool_kernel_size=pool_kernel_sizes[1],\n","                           pool_stride=pool_strides[1])\n","\n","    self.conv3 = ConvBlock(in_channels=channels[1], out_channels=channels[2],\n","                           conv_kernel_size=conv_kernel_sizes[2],\n","                           conv_stride=conv_strides[2],\n","                           conv_padding=conv_paddings[2],\n","                           inc_pool=pool_masks[2],\n","                           pool_kernel_size=pool_kernel_sizes[2],\n","                           pool_stride=pool_strides[2])\n","    \n","    self.conv4 = ConvBlock(in_channels=channels[2], out_channels=channels[3],\n","                           conv_kernel_size=conv_kernel_sizes[3],\n","                           conv_stride=conv_strides[3],\n","                           conv_padding=conv_paddings[3],\n","                           inc_pool=pool_masks[3],\n","                           pool_kernel_size=pool_kernel_sizes[3],\n","                           pool_stride=pool_strides[3])\n","    \n","    self.conv5 = ConvBlock(in_channels=channels[3], out_channels=channels[4],\n","                           conv_kernel_size=conv_kernel_sizes[4],\n","                           conv_stride=conv_strides[4],\n","                           conv_padding=conv_paddings[4],\n","                           inc_pool=pool_masks[4],\n","                           pool_kernel_size=pool_kernel_sizes[4],\n","                           pool_stride=pool_strides[4])\n","    \n","    # calculate size for linear layers\n","    sample_output1 = self.conv1(torch.from_numpy(\n","        single_sample[np.newaxis,...].astype(np.float32)))\n","    sample_output2 = self.conv2(sample_output1)\n","    sample_output3 = self.conv3(sample_output2)\n","    sample_output4 = self.conv4(sample_output3)\n","    sample_output5 = self.conv5(sample_output4)\n","    sample_flattened = sample_output5.flatten(start_dim=1)\n","\n","\n","    # linear blocks\n","    self.linear1 = LinearBlock(in_features=(sample_flattened.shape[1]),\n","                                            out_features=(linear_features[0]),\n","                                            dropout_prob=dropout_probs[0])\n","    self.linear2 = LinearBlock(in_features=(linear_features[0]),\n","                                            out_features=(linear_features[1]),\n","                                            dropout_prob=dropout_probs[1])\n","    self.head = HeadBlock(in_features=(linear_features[1]))\n","  \n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.conv2(x)\n","    x = self.conv3(x)\n","    x = self.conv4(x)\n","    x = self.conv5(x)\n","    x = x.flatten(start_dim=1)\n","    x = self.linear1(x)\n","    x = self.linear2(x)\n","    x = self.head(x)\n","    return x\n","\n","models_dict = {\n","    \"Conv_1_layer\": Conv1Layer,\n","    \"Conv_3_layer\": Conv3Layer,\n","    \"Conv_5_layer\": Conv5Layer,\n","}"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o8OQ_fe3ztUA"},"source":["# Loop through trained models in a given folder"]},{"cell_type":"code","metadata":{"id":"u8AJbOAxz0kc","executionInfo":{"status":"ok","timestamp":1619484745889,"user_tz":240,"elapsed":254,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["CHECKPOINT_ROOT = \"/content/drive/MyDrive/ITCS 5156 project/trained_models/\""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5vRA8Qay0CQk","executionInfo":{"status":"ok","timestamp":1619485008231,"user_tz":240,"elapsed":248,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["import os\n","checkpoint_dir = CHECKPOINT_ROOT + \"CNN tests 4-25/\"\n","\n","checkpoints = os.listdir(checkpoint_dir)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIW0rZlx19FO","executionInfo":{"status":"ok","timestamp":1619485255243,"user_tz":240,"elapsed":225,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["model.load_state_dict?"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EE5YYdj1Ch0","executionInfo":{"status":"ok","timestamp":1619485410492,"user_tz":240,"elapsed":253,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"18eb5129-9f6c-4328-80db-6e02f73fc2ef"},"source":["for checkpoint in checkpoints:\n","  check = torch.load(checkpoint_dir + checkpoint)\n","\n","  print(check.keys())\n","  print(check['model_id'])\n","  #model = models_dict[check['model_id']]()\n","  #print(check['model_state_dict'])\n","  #model.load_state_dict(check['model_state_dict'])\n","  print(check['notes'])\n","  print(checkpoint, \" loaded\")\n","  break"],"execution_count":26,"outputs":[{"output_type":"stream","text":["dict_keys(['filename', 'epochs', 'model_id', 'model_state_dict', 'avg_train_loss_hist', 'std_train_loss_hist', 'avg_val_loss_hist', 'std_val_loss_hist', 'train_acc_hist', 'val_acc_hist', 'train_prec_hist', 'train_recall_hist', 'train_f1_hist', 'val_prec_hist', 'val_recall_hist', 'val_f1_hist', 'dataset_info', 'notes', 'summary', 'experiment_params'])\n","Conv_1_layer\n","\n","      Model trained on 4-25.\n","      Varying the number of convolutional layers while only applying maxPooling\n","      in the temporal direction. \n","\n","      This network has 1 convolutional layers with channels: [8]\n","\n","      Other params: \n","      max epochs = 100\n","      interval (for output) = 16\n","      lr = 0.0001\n","      batch_size = 64\n","      criterion = CrossEntropyLoss\n","      No dropout layers in linear portion\n","      buffer (for early stopping) = 0.05\n","\n","      Model summary: \n","      ==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","├─ConvBlock: 1-1                         [-1, 64, 13, 258]         --\n","|    └─Sequential: 2-1                   [-1, 64, 13, 258]         --\n","|    |    └─Conv2d: 3-1                  [-1, 64, 13, 517]         640\n","|    |    └─ReLU: 3-2                    [-1, 64, 13, 517]         --\n","|    |    └─MaxPool2d: 3-3               [-1, 64, 13, 258]         --\n","|    |    └─BatchNorm2d: 3-4             [-1, 64, 13, 258]         128\n","├─ConvBlock: 1-2                         [-1, 64, 13, 129]         --\n","|    └─Sequential: 2-2                   [-1, 64, 13, 129]         --\n","|    |    └─Conv2d: 3-5                  [-1, 64, 13, 258]         36,928\n","|    |    └─ReLU: 3-6                    [-1, 64, 13, 258]         --\n","|    |    └─MaxPool2d: 3-7               [-1, 64, 13, 129]         --\n","|    |    └─BatchNorm2d: 3-8             [-1, 64, 13, 129]         128\n","├─ConvBlock: 1-3                         [-1, 64, 13, 64]          --\n","|    └─Sequential: 2-3                   [-1, 64, 13, 64]          --\n","|    |    └─Conv2d: 3-9                  [-1, 64, 13, 129]         36,928\n","|    |    └─ReLU: 3-10                   [-1, 64, 13, 129]         --\n","|    |    └─MaxPool2d: 3-11              [-1, 64, 13, 64]          --\n","|    |    └─BatchNorm2d: 3-12            [-1, 64, 13, 64]          128\n","├─ConvBlock: 1-4                         [-1, 128, 13, 32]         --\n","|    └─Sequential: 2-4                   [-1, 128, 13, 32]         --\n","|    |    └─Conv2d: 3-13                 [-1, 128, 13, 64]         73,856\n","|    |    └─ReLU: 3-14                   [-1, 128, 13, 64]         --\n","|    |    └─MaxPool2d: 3-15              [-1, 128, 13, 32]         --\n","|    |    └─BatchNorm2d: 3-16            [-1, 128, 13, 32]         256\n","├─ConvBlock: 1-5                         [-1, 128, 13, 16]         --\n","|    └─Sequential: 2-5                   [-1, 128, 13, 16]         --\n","|    |    └─Conv2d: 3-17                 [-1, 128, 13, 32]         147,584\n","|    |    └─ReLU: 3-18                   [-1, 128, 13, 32]         --\n","|    |    └─MaxPool2d: 3-19              [-1, 128, 13, 16]         --\n","|    |    └─BatchNorm2d: 3-20            [-1, 128, 13, 16]         256\n","├─LinearBlock: 1-6                       [-1, 128]                 --\n","|    └─Sequential: 2-6                   [-1, 128]                 --\n","|    |    └─Linear: 3-21                 [-1, 128]                 3,408,000\n","|    |    └─ReLU: 3-22                   [-1, 128]                 --\n","|    |    └─BatchNorm1d: 3-23            [-1, 128]                 256\n","|    |    └─Dropout: 3-24                [-1, 128]                 --\n","├─LinearBlock: 1-7                       [-1, 64]                  --\n","|    └─Sequential: 2-7                   [-1, 64]                  --\n","|    |    └─Linear: 3-25                 [-1, 64]                  8,256\n","|    |    └─ReLU: 3-26                   [-1, 64]                  --\n","|    |    └─BatchNorm1d: 3-27            [-1, 64]                  128\n","|    |    └─Dropout: 3-28                [-1, 64]                  --\n","├─HeadBlock: 1-8                         [-1, 11]                  --\n","|    └─Sequential: 2-8                   [-1, 11]                  --\n","|    |    └─Linear: 3-29                 [-1, 11]                  715\n","==========================================================================================\n","Total params: 3,714,187\n","Trainable params: 3,714,187\n","Non-trainable params: 0\n","Total mult-adds (M): 322.86\n","==========================================================================================\n","Input size (MB): 0.03\n","Forward/backward pass size (MB): 10.43\n","Params size (MB): 14.17\n","Estimated Total Size (MB): 24.63\n","==========================================================================================\n","\n","\n"," stopped early\n","1_layers_channel_0_AsymPool.pt  loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PYkvWCP3zie_"},"source":["from os import path, walk\n","\n","EXISTING_CHECKPOINTS = []\n","UNIQUE_CHECKPOINTS = set()\n","for root, _, files in walk(CHECKPOINT_PATH):\n","  for i, file in enumerate(files):\n","    if file.endswith('.pt'):\n","      model_dict = torch.load(path.join(root, file))\n","      EXISTING_CHECKPOINTS.append(model_dict)\n","      UNIQUE_CHECKPOINTS.add(model_dict['model_id'])"],"execution_count":null,"outputs":[]}]}