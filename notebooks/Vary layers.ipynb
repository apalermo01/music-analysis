{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Vary layers.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOjRPF9l05GGfp91FAFzdfd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qCYSVjCgxP9G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XVf2IpNhxokr"},"source":["# Imports / paths"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6G4MUI7xrxy","executionInfo":{"status":"ok","timestamp":1619529910953,"user_tz":240,"elapsed":3474,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"dfd9471b-a0d7-4918-fb0d-2b9feb5e4948"},"source":["! pip install torch-summary"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torch-summary\n","  Downloading https://files.pythonhosted.org/packages/ca/db/93d18c84f73b214acfa4d18051d6f4263eee3e044c408928e8abe941a22c/torch_summary-1.4.5-py3-none-any.whl\n","Installing collected packages: torch-summary\n","Successfully installed torch-summary-1.4.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ln3x-Zdx2Sc","executionInfo":{"status":"ok","timestamp":1619529940958,"user_tz":240,"elapsed":33471,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"ec0bd250-66d3-4d27-9dda-676a2ef0e734"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import pandas as pd\n","import json\n","from torchsummary import summary\n","import time\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import precision_recall_fscore_support\n","import librosa.display\n","import math\n","import os\n","from textwrap import dedent\n","\n","IRMAS_PATH = \"/content/drive/MyDrive/ITCS 5156 project/IRMAS dataset/IRMAS-TrainingData/\"\n","JSON_PATH = \"/content/drive/MyDrive/ITCS 5156 project/IRMAS dataset/json_files/\"\n","filename = \"irmas_data_mfcc13_hop_length256_n_fft2048.json\"\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aSwNPE4kyA9t"},"source":["# Dataset / Preprocessing"]},{"cell_type":"code","metadata":{"id":"AaLYxQywx2-p","executionInfo":{"status":"ok","timestamp":1619529943031,"user_tz":240,"elapsed":282,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["class IRMASDataset(Dataset):\n","  def __init__(self, JSON_PATH=JSON_PATH, filename=filename, transform=None):\n","    with open(JSON_PATH + filename, \"r\") as f:\n","      self.irmas_data = json.load(f)\n","    self.metadata = self.irmas_data.pop('metadata') \n","    self.instruments = [\"cel\", \"cla\", \"flu\", \"gac\", \"gel\", \"org\", \"pia\", \"sax\",\n","    \"tru\", \"vio\", \"voi\"]\n","    self.encoder = LabelEncoder()\n","    self.encoder.fit(self.instruments)\n","\n","  def __len__(self):\n","    return len(self.irmas_data)\n","\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = np.array(idx.tolist())\n","\n","    mfccs = np.array(self.irmas_data[str(idx)]['mfccs'])[np.newaxis,...]\n","\n","    primary_instrument = self.encoder.transform(\n","      [np.array(self.irmas_data[str(idx)]['primary_instrument'])]\n","    )\n","    sample = {'mfccs': mfccs, 'instrument': primary_instrument, 'metadata': self.metadata}\n","    return sample\n","\n","def prep_dataset(filename=filename, val_split=0.2, batch_size=1):\n","\n","  dataset = IRMASDataset(JSON_PATH=JSON_PATH, filename=filename)\n","  train_set, val_set = random_split(dataset, [round(len(dataset) * (1-val_split)), round(len(dataset)*val_split)])\n","\n","  train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n","  val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n","\n","  return train_loader, val_loader, dataset"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E8kVKwZ9yJIe"},"source":["# Architectures"]},{"cell_type":"code","metadata":{"id":"zSK4dT7EyGzi","executionInfo":{"status":"ok","timestamp":1619530731125,"user_tz":240,"elapsed":1141,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["################################################################################\n","#################################### BLOCKS ####################################\n","################################################################################\n","\n","class ConvBlock(nn.Module):\n","\n","\tdef __init__(self, in_channels, out_channels, conv_kernel_size=3,\n","\t\t\t\t\t\t\t conv_stride=1, conv_padding=0,\n","\t\t\t\t\t\t\t inc_pool=True, pool_kernel_size=2, pool_stride=2):\n","\t\t\"\"\"Convolutional block with conv2d, linear activation, max pooling, \n","\t\t\tand batch norm\n","\t\t:param in_channels:\n","\t\t:param out_channels:\n","\t\t:param conv_kernel_size:\n","\t\t:param conv_stride:\n","\t\t:param conv_padding:\n","\t\t:param inc_pool: If true, includes a max pooling layer\n","\n","\t\tThe following params only matter if inc_pool is True\n","\t\t:param pool_kernel_size:\n","\t\t:param pool_stride:\n","\t\t\"\"\"\n","\t\tsuper(ConvBlock, self).__init__()\n","\n","\t\t# construct sequential blocks\n","\t\tif inc_pool:\n","\t\t\tself.conv_block = nn.Sequential(\n","\t\t\t\t\t\tnn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n","\t\t\t\t\t\t\t\t\t\tkernel_size=conv_kernel_size, stride=conv_stride,\n","\t\t\t\t\t\t\t\t\t\t\tpadding=conv_padding),\n","\t\t\t\t\t\tnn.ReLU(),\n","\t\t\t\t\t\tnn.MaxPool2d(kernel_size=pool_kernel_size, stride=pool_stride),\n","\t\t\t\t\t\tnn.BatchNorm2d(num_features=out_channels)\n","\t\t\t\t)\n","\t\telse:\n","\t\t\tself.conv_block = nn.Sequential(\n","\t\t\t\t\t\tnn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n","\t\t\t\t\t\t\t\t\t\t\tkernel_size=conv_kernel_size, stride=conv_stride,\n","\t\t\t\t\t\t\t\t\t\t\tpadding=conv_padding),\n","\t\t\t\t\t\tnn.ReLU(),\n","\t\t\t\t\t\tnn.BatchNorm2d(num_features=out_channels)\n","\t\t\t\t) \n","\n","\t# run forward\n","\tdef forward(self, x):\n","\t\tx = self.conv_block(x)\n","\t\treturn x\n","\n","class LinearBlock(nn.Module):\n","\n","\tdef __init__(self, in_features, out_features, dropout_prob=0):\n","\t\t\"\"\"Linear block with dense layer, relu, batch norm, then dropout\n","\t\t:param in_features:\n","\t\t:param out_features:\n","\t\t:param dropout_prob: Set to 0 for no dropout layer\n","\t\t\"\"\"\n","\n","\t\tsuper(LinearBlock, self).__init__()\n","\t\tself.linear_block = nn.Sequential(\n","\t\t\t\tnn.Linear(in_features=in_features, out_features=out_features),\n","\t\t\t\tnn.ReLU(),\n","\t\t\t\tnn.BatchNorm1d(num_features=out_features),\n","\t\t\t\tnn.Dropout(p=dropout_prob)\n","\t\t)\n","\n","\tdef forward(self, x):\n","\t\tx = self.linear_block(x)\n","\t\treturn x\n","\n","class HeadBlock(nn.Module):\n","\n","\tdef __init__(self, in_features):\n","\t\t\"\"\"Linear block with softmax output.\n","\t\tNOTE: no longer using softmax output since the CrossEntropyLoss handles that\n","\t\t:param in_features:\n","\t\tout_features is fixed to 11 to corrospond to the number of classes\n","\t\t\"\"\"\n","\t\tsuper(HeadBlock, self).__init__()\n","\t\tself.head_block = nn.Sequential(\n","\t\t\t\tnn.Linear(in_features=in_features, out_features=11),\n","\t\t\t\t#nn.Softmax()\n","\t\t)\n","\n","\tdef forward(self, x):\n","\t\tx = self.head_block(x)\n","\t\treturn x\n","\n","################################################################################\n","################################### NETWORKS ###################################\n","################################################################################\n","class Conv1Layer(nn.Module):\n","\n","\tdef __init__(self, single_sample, channels=[8],\n","\t\t\t\t\t\t\t conv_kernel_sizes=[3],\n","\t\t\t\t\t\t\t conv_strides=[1],\n","\t\t\t\t\t\t\t conv_paddings=[0],\n","\t\t\t\t\t\t\t pool_masks=[True],\n","\t\t\t\t\t\t\t pool_kernel_sizes=[2],\n","\t\t\t\t\t\t\t pool_strides=[2],\n","\t\t\t\t\t\t\t linear_features=[128, 64],\n","\t\t\t\t\t\t\t dropout_probs=[0, 0]):\n","\n","\t\t\"\"\"Convolutional neural network with 1 conv layer and 3 linear layers.\n","\t\tAll hyperparams are flexible and initialized using lists (or array-likes).\n","\t\tThe nth entry in each list corrosponds to the nth layer\n","\n","\t\t:param single_sample: a sample mfcc to run through the network on init to \n","\t\tget layer sizes\n","\t\t:param channels:\n","\t\t:param conv_kernel_sizes:\n","\t\t:param conv_paddings:\n","\t\t:param pool_masks: array of booleans to control max pooling\n","\t\t\tex: [False, True] means no max pooling after 1st layer, but max pooling \n","\t\t\tafter second layer. Other hyperparams for maxpooling must be passed so\n","\t\t\tthat alignment is consistent. ex: in the [False, True] example, one could\n","\t\t\tpass [3, 2] for pool kernel size. The 3 does nothing but the 2 will use \n","\t\t\ta pool kernel size of 2. Passing only [2] will result in an error even if \n","\t\t\tthere is only one maxpool layer.\n","\t\t:param pool_kernel_sizes:\n","\t\t:param pool_strides:\n","\t\t:param linear features: output sizes for linear layers (input size\n","\t\t\tdetermined on init by one_mfcc)\n","\t\t:param dropout_probs:\n","\n","\t\t\"\"\"\n","\t\tsuper(Conv1Layer, self).__init__()\n","\n","\t\t# convolutional blocks\n","\t\tself.conv1 = ConvBlock(in_channels=1, out_channels=channels[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[0])\n","\t\n","\t\t# run a single sample through the convolutional block to get output size\n","\t\t# https://discuss.pytorch.org/t/convolution-and-pooling-layers-need-a-method-to-calculate-output-size/21895\n","\t\tsample_output1 = self.conv1(torch.from_numpy(\n","\t\t\t\tsingle_sample[np.newaxis,...].astype(np.float32)))\n","\t\n","\t\tsample_flattened = sample_output1.flatten(start_dim=1)\n"," \n","\t\t# linear blocks\n","\t\tself.linear1 = LinearBlock(in_features=(sample_flattened.shape[1]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tout_features=(linear_features[0]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdropout_prob=dropout_probs[0])\n","\t\tself.linear2 = LinearBlock(in_features=(linear_features[0]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tout_features=(linear_features[1]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdropout_prob=dropout_probs[1])\n","\t\tself.head = HeadBlock(in_features=(linear_features[1]))\n","\n","\tdef forward(self, x):\n","\t\tx = self.conv1(x)\n","\t\tx = x.flatten(start_dim=1)\n","\t\tx = self.linear1(x)\n","\t\tx = self.linear2(x)\n","\t\tx = self.head(x)\n","\t\treturn x\n","\n","class Conv3Layer(nn.Module):\n","\tdef __init__(self, single_sample, channels=[8, 16, 32],\n","\t\t\t\t\t\t\t conv_kernel_sizes=[3, 3, 3],\n","\t\t\t\t\t\t\t conv_strides=[1, 1, 1],\n","\t\t\t\t\t\t\t conv_paddings=[0, 0, 1,],\n","\t\t\t\t\t\t\t pool_masks=[True, False, False],\n","\t\t\t\t\t\t\t pool_kernel_sizes=[2, 2, 2],\n","\t\t\t\t\t\t\t pool_strides=[2, 2, 2],\n","\t\t\t\t\t\t\t linear_features=[128, 64],\n","\t\t\t\t\t\t\t dropout_probs=[0, 0]):\n","\n","\t\t\"\"\"Convolutional neural network with 3 conv layers and 3 linear layers.\n","\t\tAll hyperparams are flexible and initialized using lists (or array-likes).\n","\t\tThe nth entry in each list corrosponds to the nth layer\n","\n","\t\t:param single_sample: a sample mfcc to run through the network on init to \n","\t\tget layer sizes\n","\t\t:param channels:\n","\t\t:param conv_kernel_sizes:\n","\t\t:param conv_paddings:\n","\t\t:param pool_masks: array of booleans to control max pooling\n","\t\t\tex: [False, True] means no max pooling after 1st layer, but max pooling \n","\t\t\tafter second layer. Other hyperparams for maxpooling must be passed so\n","\t\t\tthat alignment is consistent. ex: in the [False, True] example, one could\n","\t\t\tpass [3, 2] for pool kernel size. The 3 does nothing but the 2 will use \n","\t\t\ta pool kernel size of 2. Passing only [2] will result in an error even if \n","\t\t\tthere is only one maxpool layer.\n","\t\t:param pool_kernel_sizes:\n","\t\t:param pool_strides:\n","\t\t:param linear features: output sizes for linear layers (input size\n","\t\t\tdetermined on init by one_mfcc)\n","\t\t:param dropout_probs:\n","\t\t\"\"\"\n","\n","\t\tsuper(Conv3Layer, self).__init__()\n","\n","\t\tself.conv1 = ConvBlock(in_channels=1, out_channels=channels[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[0])\n","\t\t\n","\t\tself.conv2 = ConvBlock(in_channels=channels[0], out_channels=channels[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[1])\n","\n","\t\tself.conv3 = ConvBlock(in_channels=channels[1], out_channels=channels[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[2])\n","\t\t\n","\t\t# calculate size for linear layers\n","\t\tsample_output1 = self.conv1(torch.from_numpy(\n","\t\t\t\tsingle_sample[np.newaxis,...].astype(np.float32)))\n","\t\tsample_output2 = self.conv2(sample_output1)\n","\t\tsample_output3 = self.conv3(sample_output2)\n","\t\tsample_flattened = sample_output3.flatten(start_dim=1)\n","\n","\t\t# linear blocks\n","\t\tself.linear1 = LinearBlock(in_features=(sample_flattened.shape[1]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tout_features=(linear_features[0]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdropout_prob=dropout_probs[0])\n","\t\tself.linear2 = LinearBlock(in_features=(linear_features[0]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tout_features=(linear_features[1]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdropout_prob=dropout_probs[1])\n","\t\tself.head = HeadBlock(in_features=(linear_features[1]))\n","\t\n","\tdef forward(self, x):\n","\t\tx = self.conv1(x)\n","\t\tx = self.conv2(x)\n","\t\tx = self.conv3(x)\n","\t\tx = x.flatten(start_dim=1)\n","\t\tx = self.linear1(x)\n","\t\tx = self.linear2(x)\n","\t\tx = self.head(x)\n","\t\treturn x\n","\n","class Conv5Layer(nn.Module):\n","\tdef __init__(self, single_sample, channels= [8, 8, 32, 32, 64],\n","\t\t\t\t\t\t\t conv_kernel_sizes=[3, 3, 3, 3, 3],\n","\t\t\t\t\t\t\t conv_strides=[1, 1, 1, 1, 1],\n","\t\t\t\t\t\t\t conv_paddings=[0, 0, 1, 1, 1],\n","\t\t\t\t\t\t\t pool_masks=[True, False, False, False, False],\n","\t\t\t\t\t\t\t pool_kernel_sizes=[2, 2, 2, 2, 2],\n","\t\t\t\t\t\t\t pool_strides=[2, 2, 2, 2, 2],\n","\t\t\t\t\t\t\t linear_features=[128, 64],\n","\t\t\t\t\t\t\t dropout_probs=[0, 0]):\n","\t\t\n","\t\t\"\"\"Convolutional neural network with 3 conv layers and 3 linear layers.\n","\t\tAll hyperparams are flexible and initialized using lists (or array-likes).\n","\t\tThe nth entry in each list corrosponds to the nth layer\n","\n","\t\t:param single_sample: a sample mfcc to run through the network on init to \n","\t\tget layer sizes\n","\t\t:param channels:\n","\t\t:param conv_kernel_sizes:\n","\t\t:param conv_paddings:\n","\t\t:param pool_masks: array of booleans to control max pooling\n","\t\t\tex: [False, True] means no max pooling after 1st layer, but max pooling \n","\t\t\tafter second layer. Other hyperparams for maxpooling must be passed so\n","\t\t\tthat alignment is consistent. ex: in the [False, True] example, one could\n","\t\t\tpass [3, 2] for pool kernel size. The 3 does nothing but the 2 will use \n","\t\t\ta pool kernel size of 2. Passing only [2] will result in an error even if \n","\t\t\tthere is only one maxpool layer.\n","\t\t:param pool_kernel_sizes:\n","\t\t:param pool_strides:\n","\t\t:param linear features: output sizes for linear layers (input size\n","\t\t\tdetermined on init by one_mfcc)\n","\t\t:param dropout_probs:\n","\t\t\"\"\"\n","\n","\t\tsuper(Conv5Layer, self).__init__()\n","\n","\t\t# convolutional layers\n","\t\tself.conv1 = ConvBlock(in_channels=1, out_channels=channels[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[0],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[0])\n","\t\t\n","\t\tself.conv2 = ConvBlock(in_channels=channels[0], out_channels=channels[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[1],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[1])\n","\n","\t\tself.conv3 = ConvBlock(in_channels=channels[1], out_channels=channels[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[2],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[2])\n","\t\t\n","\t\tself.conv4 = ConvBlock(in_channels=channels[2], out_channels=channels[3],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[3],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[3],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[3],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[3],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[3],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[3])\n","\t\t\n","\t\tself.conv5 = ConvBlock(in_channels=channels[3], out_channels=channels[4],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_kernel_size=conv_kernel_sizes[4],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_stride=conv_strides[4],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t conv_padding=conv_paddings[4],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t inc_pool=pool_masks[4],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_kernel_size=pool_kernel_sizes[4],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t pool_stride=pool_strides[4])\n","\t\t\n","\t\t# calculate size for linear layers\n","\t\tsample_output1 = self.conv1(torch.from_numpy(\n","\t\t\t\tsingle_sample[np.newaxis,...].astype(np.float32)))\n","\t\tsample_output2 = self.conv2(sample_output1)\n","\t\tsample_output3 = self.conv3(sample_output2)\n","\t\tsample_output4 = self.conv4(sample_output3)\n","\t\tsample_output5 = self.conv5(sample_output4)\n","\t\tsample_flattened = sample_output5.flatten(start_dim=1)\n","\n","\n","\t\t# linear blocks\n","\t\tself.linear1 = LinearBlock(in_features=(sample_flattened.shape[1]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tout_features=(linear_features[0]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdropout_prob=dropout_probs[0])\n","\t\tself.linear2 = LinearBlock(in_features=(linear_features[0]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tout_features=(linear_features[1]),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdropout_prob=dropout_probs[1])\n","\t\tself.head = HeadBlock(in_features=(linear_features[1]))\n","\t\n","\tdef forward(self, x):\n","\t\tx = self.conv1(x)\n","\t\tx = self.conv2(x)\n","\t\tx = self.conv3(x)\n","\t\tx = self.conv4(x)\n","\t\tx = self.conv5(x)\n","\t\tx = x.flatten(start_dim=1)\n","\t\tx = self.linear1(x)\n","\t\tx = self.linear2(x)\n","\t\tx = self.head(x)\n","\t\treturn x\n","\n","### This one doesn't seem to be working yet\n","class ConvNLayer(nn.Module):\n","\tdef __init__(self, single_sample, \n","\n","\t\tnum_conv_layers=2,\n","\t\tchannels=[8, 16],\n","\t\tconv_kernel_sizes=[3, 3],\n","\t\tconv_strides=[1, 1],\n","\t\tconv_paddings=[1, 1],\n","\t\tpool_masks=[True, True],\n","\t\tpool_kernel_sizes=[2, 2],\n","\t\tpool_strides=[2, 2],\n","\t\t\n","\t\tnum_linear_layers=2,\n","\t\tlinear_features=[128, 64],\n","\t\tdropout_probs=[0, 0]\n","\t\t):\n","\t\t\"\"\"Convolutional neural net with an arbitrary number of convolutional layers\n","\t\t\"\"\"\n","\t\tsuper(ConvNLayer, self).__init__()\n","\n","\t\tself.num_conv_layers = num_conv_layers\n","\t\tself.num_linear_layers = num_linear_layers\n","\n","\t\t# prepend 1 to input channels since there is only one\n","\t\tchannels.insert(0, 1)\n","\n","\t\t# define list of convolutional layers\n","\t\tself.conv_layers = [\n","\t\t\tConvBlock(\n","\t\t\t\tin_channels = channels[i],\n","\t\t\t\tout_channels = channels[i+1],\n","\t\t\t\tconv_kernel_size = conv_kernel_sizes[i],\n","\t\t\t\tconv_stride = conv_strides[i],\n","\t\t\t\tconv_padding = conv_paddings[i],\n","\t\t\t\tinc_pool = pool_masks[i],\n","\t\t\t\tpool_kernel_size = pool_kernel_sizes[i],\n","\t\t\t\tpool_stride = pool_strides[i])\n","\t\tfor i in range(self.num_conv_layers)]\n","\n","\t\t# calculate size of linear layers\n","\t\tsample = torch.from_numpy(\n","\t\t\tsingle_sample[np.newaxis,...].astype(np.float32)\n","\t\t)\n","\n","\t\tfor i in range(self.num_conv_layers):\n","\t\t\tsample = self.conv_layers[i](sample)\n","\n","\t\tsample_flattened = sample.flatten(start_dim=1)\n","\n","\t\t# prepend shape of input to linear block\n","\t\tlinear_features.insert(0, sample_flattened.shape[1])\n","\n","\t\t# define list of linear layers\n","\t\tself.linear_layers = [\n","\t\t\tLinearBlock(\n","\t\t\t\tin_features = (linear_features[i]),\n","\t\t\t\tout_features = (linear_features[i+1]),\n","\t\t\t\tdropout_prob = dropout_probs[i])\n","\t\t\tfor i in range(self.num_linear_layers)\n","\t\t]\n","\n","\t\t# define output head\n","\t\tself.head = HeadBlock(in_features=(linear_features[-1]))\n","\n","\tdef forward(self, x):\n","\t\tfor i in range(self.num_conv_layers):\n","\t\t\tprint(self.conv_layers[i])\n","\t\t\tx = self.conv_layers[i](x)\n","\t\t\n","\t\tx = x.flatten(start_dim=1)\n","\n","\t\tfor i in range(self.num_linear_layers):\n","\t\t\tx = self.linear_layers[i](x)\n","\t\t\n","\t\tx = self.head(x)\n","\t\treturn x\n","\n","models_dict = {\n","\t\"Conv_1_layer\": Conv1Layer,\n","\t\"Conv_3_layer\": Conv3Layer,\n","\t\"Conv_5_layer\": Conv5Layer,\n","\t\"Conv_N_layer\": ConvNLayer,\n","}"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pjr3RAfVyfgB"},"source":["# Get a sample & test"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bp5qY0JmyWee","executionInfo":{"status":"ok","timestamp":1619529983018,"user_tz":240,"elapsed":32252,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"98fd38a8-f16c-4f79-9a5c-3f8acc605b9e"},"source":["train_loader, val_loader, dataset = prep_dataset(\n","      filename=filename, batch_size=5, val_split=0.2)\n","single_sample = dataset[0]\n","\n","one_mfcc = np.array(single_sample['mfccs'])\n","one_mfcc.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 13, 517)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"LcemxF9NymoP"},"source":["# Train Loop"]},{"cell_type":"code","metadata":{"id":"5av__3mSyj9_","executionInfo":{"status":"ok","timestamp":1619531550085,"user_tz":240,"elapsed":859,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}}},"source":["def train_model(filename=\"irmas_data_mfcc13_hop_length256_n_fft2048\", model_id=\"TestModel\",\n","                num_epochs=2, interval=16, lr=0.001, batch_size=64,\n","                val_split=0.2, save_checkpoint=False, checkpoint_path=\"\",\n","                notes=\"\", checkpoint_name=\"utitled.pt\", criterion=torch.nn.NLLLoss(),\n","                patience=None, min_epochs=5, buffer=0.05, dropout_prob=None,\n","                model_args={}, experiment_params={}):\n","  \"\"\"Model training loop for music analysis project. Currently, this loop only supports\n","  models that take input in the shape [mini_batch, channels, L, W].\n","\n","  :param filename:\n","  :param model_id:\n","  :param num_epochs:\n","  :param interval:\n","  :param lr:\n","  :param batch_size:\n","  :param val_split:\n","  :param save_checkpoint:\n","  :param checkpoint_path:\n","  :param notes:\n","  :param checkpoint name:\n","  :param criterion:\n","  :param patience: If validation loss does not improve over this many epochs, stop training\n","  \"\"\"\n","\n","  # Initialize device\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  print(\"device: \", device)\n","  \n","  # get train and validation set, print metadata\n","  train_loader, val_loader, dataset = prep_dataset(\n","      filename=filename, batch_size=batch_size, val_split=val_split)\n","\n","  print(\"dataset metadata: \", dataset.metadata)\n","\n","  # param for early stopping\n","  stop_next = False\n","\n","  # get number of train and validdation samples\n","  train_samples = round(len(dataset) * (1-val_split))\n","  val_samples = round(len(dataset)*val_split)\n","\n","  # initialize loss history and accuracy history for each epoch\n","  # this is the stored history for the train and validation metrics\n","  epoch_hist = []\n","  avg_train_loss_hist = []  # training loss for each epoch\n","  std_train_loss_hist = []\n","  avg_val_loss_hist = []    # validation loss for each epoch\n","  std_val_loss_hist = []\n","  train_acc_hist = []       # training accuracy for each epoch\n","  train_prec_hist = []\n","  train_recall_hist = []\n","  train_f1_hist = []\n","  val_acc_hist = []         # validation accuracy for each epoch\n","  val_prec_hist = []\n","  val_recall_hist = []\n","  val_f1_hist = []\n","\n","\n","  # get one sample to load initial shape for neural net\n","  single_sample = dataset[0]\n","  one_mfcc = np.array(single_sample['mfccs'])\n","  print(\"train model: data loaders initialized\")\n","  print(\"sample shape = \", one_mfcc.shape)\n","\n","  # initialize model\n","  model = models_dict[model_id](one_mfcc, **model_args).to(device)\n","  print(\"model loaded\")\n","  summary_str = str(summary(model, one_mfcc.shape, verbose=0))\n","\n","  print(summary_str)\n","\n","  # initialize optimizer and criterion\n","  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","  print(\"criterion: \", criterion)\n","\n","  n_train_steps = len(train_loader)\n","  n_val_steps = len(val_loader)\n","\n","  ### loop epochs\n","  for epoch in range(num_epochs):\n","    print(\"\\n\\ntraining epoch: \", epoch)\n","    epoch_hist.append(epoch+1)\n","    epoch_time_start = time.time()\n","    interval_time_start = time.time()\n","    model.to(device)\n","\n","    # at the start of the epoch, set all tracked params to zero\n","    train_losses = []\n","    val_losses = []\n","    inter_epoch_loss = []\n","    train_num_correct = 0\n","    val_num_correct = 0\n","\n","    # set params to be tracked within the epoch (\"inter-epoch\")\n","    # these will be outputted at each interval, but not saved\n","    inter_epoch_num_correct = 0\n","\n","    ### Training loop\n","    model.train()\n","    print(\"model set to train\")\n","    train_preds = []\n","    train_targets = []\n","    for i, sample in enumerate(train_loader):\n","\n","      # prep input and target tensor\n","      input_tensor = torch.from_numpy(\n","          np.array(sample['mfccs']).astype(np.float32)).to(device)\n","      targets = sample['instrument']\n","      target_tensor = torch.squeeze(torch.tensor(targets), dim=1)\n","      #print(\"target tensor after processing: \", target_tensor)\n","      train_targets.extend(list(targets.numpy()))\n","      # make predictions\n","      try:\n","        predictions = torch.squeeze(model(input_tensor).to('cpu'), dim=1)\n","      except Exception as e:\n","        print(\"EXCEPTION THROWN: \", e)\n","      # compute loss and do back-propagation\n","      loss = criterion(predictions, target_tensor)\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # append the loss to overall \n","      train_losses.append(loss.item())\n","      inter_epoch_loss.append(loss.item())\n","\n","      # compute accuracies\n","      with torch.no_grad():\n","        predictions_arr = predictions.numpy()\n","        preds = [np.argmax(predictions_arr[i]) \n","          for i in range(len(target_tensor))]\n","        # inter-epoch accuracy (reset this at each interval)\n","        inter_epoch_num_correct += np.sum([target_tensor[i] == np.argmax(predictions[i])\n","          for i in range(len(target_tensor))])\n","        \n","        # epoch accuracy (this is tracked and saved)\n","        train_num_correct += np.sum([target_tensor[i] == np.argmax(predictions[i])\n","          for i in range(len(target_tensor))])\n","        #print(\"debugging in epoch: preds = \", preds)\n","        train_preds.extend(preds)\n","\n","      # print step info\n","      if i % interval == 0:\n","\n","        # time elapsed\n","        interval_time_end = time.time()\n","\n","        # compute mean and std of losses\n","        inter_epoch_loss_avg = np.mean(inter_epoch_loss)\n","        inter_epoch_loss_std = np.std(inter_epoch_loss)\n","        \n","        # compute inter-epoch accuracy\n","        # note, this accuracy may be incorrect at the end of each epoch\n","        # when the batch size is slightly different\n","        acc = inter_epoch_num_correct / (interval*batch_size)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], step [{i+1}/{n_train_steps}], \",\n","              f\"Loss: {inter_epoch_loss_avg:.4f} +/- {inter_epoch_loss_std:.4f}, \",\n","              f\"accuracy: {acc}, \"\n","              f\"time elapsed = {interval_time_end-interval_time_start}s\")\n","        interval_time_start = time.time()\n","\n","        # reset inter_epoch metrics\n","        inter_epoch_num_correct = 0\n","        inter_epoch_loss = []\n","\n","    ### training loop finished\n","    # append the accuracy\n","    train_acc_hist.append(train_num_correct / train_samples)\n","\n","    # calculate classification metrics\n","    train_targets = np.array(train_targets).ravel()\n","    train_preds = np.array(train_preds).ravel()\n","    # print(\"debugging: train targets: \", train_targets)\n","    # print(\"debugging: train predictions: \", train_preds)\n","    train_prec, train_recall, train_f1, _ = precision_recall_fscore_support(train_targets, train_preds,\n","                                                      average='micro')\n","\n","    ### Validation loop\n","    model.eval()\n","    print(\"model set to eval\")\n","    val_preds = []\n","    val_targets = []\n","    with torch.no_grad():\n","\n","      num_correct = 0\n","      for i, sample in enumerate(val_loader):\n","        \n","        # prep input and target tensor\n","        input_tensor = torch.from_numpy(\n","            np.array(sample['mfccs']).astype(np.float32)).to(device)\n","        targets = sample['instrument']\n","        val_targets.extend(list(targets.numpy()))\n","        target_tensor = torch.squeeze(torch.tensor(targets), dim=1)\n","        #target_tensor = torch.squeeze(torch.tensor(sample['instrument']), dim=1)\n","\n","        # make predictions\n","        try:\n","          predictions = torch.squeeze(model(input_tensor).to('cpu'), dim=1)\n","        except Exception as e:\n","          print(\"EXCEPTION THROWN: \", e)\n","        # compute and append losses\n","        loss = criterion(predictions, target_tensor)\n","        val_losses.append(loss.item())\n","\n","        predictions_arr = predictions.numpy()\n","        preds = [np.argmax(predictions_arr[i]) \n","          for i in range(len(target_tensor))]\n","        val_preds.extend(preds)\n","        # get num correct to comput accuracy\n","        val_num_correct += np.sum([target_tensor[i] == np.argmax(predictions[i])\n","          for i in range(len(target_tensor))])\n","      \n","      ### validation loop finished. prep model and metrics for saving\n","      # calculate validation accuracy\n","      val_acc_hist.append(val_num_correct / val_samples)\n","      val_targets = np.array(val_targets).ravel()\n","      val_preds = np.array(val_preds).ravel()\n","      # print(\"debugging: train targets: \", train_targets)\n","      # print(\"debugging: train predictions: \", train_preds)\n","      val_prec, val_recall, val_f1, _ = precision_recall_fscore_support(val_targets, val_preds,\n","                                                      average='micro')\n","      # calculate mean and standard deviation of losses\n","      avg_train_loss = np.mean(train_losses)\n","      std_train_loss = np.std(train_losses)\n","      avg_val_loss = np.mean(val_losses)\n","      std_val_loss = np.std(val_losses)\n","\n","      # append mean and standard deviation to histories\n","      avg_train_loss_hist.append(avg_train_loss) \n","      std_train_loss_hist.append(std_train_loss)  \n","      avg_val_loss_hist.append(avg_val_loss)\n","      std_val_loss_hist.append(std_val_loss)\n","\n","      train_prec_hist.append(train_prec)\n","      train_recall_hist.append(train_recall)\n","      train_f1_hist.append(train_f1)\n","\n","      val_prec_hist.append(val_prec)\n","      val_recall_hist.append(val_recall)\n","      val_f1_hist.append(val_f1)\n","    \n","    ### epoch training finished, output results and save checkpoint\n","\n","    # text output\n","    epoch_time_end = time.time()\n","    print(f\"\\nEPOCH FINISHED: , \",\n","          f\"training: acc = {train_acc_hist[-1]:.3f}, \",\n","          f\"precision = {train_prec_hist[-1]:.3f}\",\n","          f\"recall = {train_recall_hist[-1]:.3f}\",\n","          f\"f1 = {train_f1_hist[-1]:.3f}\",\n","          f\"::: val: acc = {val_acc_hist[-1]:.3f}, \",\n","          f\"precision = {val_prec_hist[-1]:.3f}\",\n","          f\"recall = {val_recall_hist[-1]:.3f}\",\n","          f\"time elapsed = {epoch_time_end-epoch_time_start}s\")\n","    \n","    # make a plot\n","    plt.close(\"all\")\n","    fig, ax = plt.subplots(ncols=2, figsize=[15, 5])\n","    #ax.scatter(epoch_hist, avg_train_loss_hist, c='r', label=\"train loss\", )\n","    ax[0].plot(epoch_hist, avg_train_loss_hist, 'ro--', label=\"train loss\", )\n","    ax[0].errorbar(x=epoch_hist, y=avg_train_loss_hist, yerr=std_train_loss_hist,\n","                capsize=5, ls='none', color='r')\n","\n","    # ax.scatter(epoch_hist, avg_val_loss_hist, c='b', label=\"val loss\", )\n","    ax[0].plot(epoch_hist, avg_val_loss_hist, 'ko--', label=\"val loss\", )\n","    ax[0].errorbar(x=epoch_hist, y=avg_val_loss_hist, yerr=std_val_loss_hist,\n","                capsize=5, ls='none', color='k')\n","    \n","    ax[0].set_xlabel(\"epoch\")\n","    ax[0].set_ylabel(\"loss\")\n","    ax[0].legend()\n","    \n","\n","    ax[1].plot(epoch_hist, train_acc_hist, 'r-.', label=\"train accuracy\", \n","                  marker='s')\n","\n","    ax[1].plot(epoch_hist, val_acc_hist, 'k-.', label=\"val accuracy\",\n","                  marker='s')\n","    ax[1].set_ylabel(\"accuracy\")\n","    ax[1].set_xlabel(\"epoch\")\n","    ax[1].set_ylim([0, 1])\n","    ax[1].legend()\n","    fig.tight_layout(pad=1)\n","    plt.show(block=False)\n","\n","    # check validation loss if we need to stop training\n","    # print(\"validation loss hist: \", avg_val_loss_hist)\n","    # if (epoch > patience) and all(avg_val_loss_hist[-1-i] >= avg_val_loss_hist[-1-i-1]\n","    #                               for i in range(patience)):\n","    model.to('cpu')\n","    if (epoch > min_epochs) and (\n","        #avg_val_loss_hist[-1] > (std_val_loss_hist[-1] + std_train_loss_hist[-1] + avg_train_loss_hist[-1] + buffer)):\n","        (avg_val_loss_hist[-1] - avg_train_loss_hist[-1] + buffer) > (std_train_loss_hist[-1] + std_val_loss_hist[-1])\n","        or (avg_val_loss_hist[-1] > 5*avg_train_loss_hist[-1])):\n","        #avg_val_loss_hist[-1] > (std_val_loss_hist[-1] + std_train_loss_hist[-1] + buffer)):\n","                    # and any(avg_val_loss_hist[-1-i] >= avg_val_loss_hist[-1-i-1]\n","                    #                                   for i in range(patience)):\n","      # save model\n","      # TODO: refactor this so torch.save isn't repeated\n","      if save_checkpoint:\n","        notes = notes + \"\\n\\n stopped early\"\n","        torch.save({\n","            'filename': filename,\n","            'epochs': epoch_hist,\n","            'model_id': model_id,\n","            'model_state_dict': model.state_dict(),\n","            'model_args': model_args,\n","            'metrics':{\n","              'avg_train_loss_hist': avg_train_loss_hist,\n","              'std_train_loss_hist': std_train_loss_hist,\n","              'avg_val_loss_hist': avg_val_loss_hist,\n","              'std_val_loss_hist': std_val_loss_hist,\n","              'train_acc_hist': train_acc_hist,\n","              'train_prec_hist': train_prec_hist,\n","              'train_recall_hist': train_recall_hist,\n","              'train_f1_hist': train_f1_hist,\n","              'val_acc_hist': val_acc_hist,\n","              'val_prec_hist': val_prec_hist,\n","              'val_recall_hist': val_recall_hist,\n","              'val_f1_hist': val_f1_hist,},\n","            'dataset_info': dataset.metadata,\n","            'notes': notes,\n","            'summary': summary_str,\n","            'experiment_params': experiment_params,\n","        }, checkpoint_path+checkpoint_name)\n","        print(\"model saved\")\n","\n","      if stop_next:\n","        print(\"stopping early\")\n","        break\n","      else:\n","        stop_next = True\n","    else:\n","      stop_next = False\n","\n","    # save model\n","    if save_checkpoint:\n","      torch.save({\n","            'filename': filename,\n","            'epochs': epoch_hist,\n","            'model_id': model_id,\n","            'model_state_dict': model.state_dict(),\n","            'model_args': model_args,\n","            'metrics':{\n","              'avg_train_loss_hist': avg_train_loss_hist,\n","              'std_train_loss_hist': std_train_loss_hist,\n","              'avg_val_loss_hist': avg_val_loss_hist,\n","              'std_val_loss_hist': std_val_loss_hist,\n","              'train_acc_hist': train_acc_hist,\n","              'train_prec_hist': train_prec_hist,\n","              'train_recall_hist': train_recall_hist,\n","              'train_f1_hist': train_f1_hist,\n","              'val_acc_hist': val_acc_hist,\n","              'val_prec_hist': val_prec_hist,\n","              'val_recall_hist': val_recall_hist,\n","              'val_f1_hist': val_f1_hist,},\n","            'dataset_info': dataset.metadata,\n","            'notes': notes,\n","            'summary': summary_str,\n","            'experiment_params': experiment_params,\n","        }, checkpoint_path+checkpoint_name)\n","      print(\"model saved\")"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-YWf2lDzASm"},"source":["# Initialize params"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1zSJO9fss_5FtXKG_N3nb3ZKPfm-_Pz3V"},"id":"I2mXe_BTy5qg","executionInfo":{"status":"error","timestamp":1619538394552,"user_tz":240,"elapsed":3866799,"user":{"displayName":"Alex Palermo","photoUrl":"","userId":"06488501085160491296"}},"outputId":"ea9318ec-775a-4fbc-8633-ff9d75899d7a"},"source":["CHECKPOINT_ROOT = \"/content/drive/MyDrive/ITCS 5156 project/trained_models/layers/\"\n","\n","model_args = {\n","\t\"channels\": [8, 8, 32, 32, 64],\n","\t\"conv_kernel_sizes\": [3, 3, 3, 3, 3],\n","\t\"conv_strides\": [1, 1, 1, 1, 1],\n","\t\"conv_paddings\": [1, 1, 1, 1, 1],\n","\t\"pool_masks\": [True, True, True, True, True],\n","\t\"pool_kernel_sizes\": [2, 2, 2, (1, 2), (1, 2)],\n","\t\"pool_strides\": [2, 2, 2, (1, 2), (1, 2)],\n","\t\"linear_features\": [128, 64],\n","\t\"dropout_probs\": [0, 0],\n","}\n","\n","args_dict = {\n","\t\"filename\": filename, \n","\t\"model_id\": \"Conv_5_layer\",\n","\t\"num_epochs\": 100,\n","\t\"interval\": 16,\n","\t\"batch_size\": 32,\n","\t\"val_split\": 0.2,\n","\t\"save_checkpoint\": True,\n","\t\"criterion\": nn.CrossEntropyLoss(),\n","\t\"patience\": 2,\n","\t\"min_epochs\": 3,\n","\t\"buffer\": 0.05,\n","  \"lr\": 0.01,\n","\t\"model_args\": model_args,\n","  'checkpoint_path': CHECKPOINT_ROOT,\n","}\n","\n","model_ids = [\"Conv_1_layer\", \"Conv_3_layer\", \"Conv_5_layer\"]\n","pool_types = [\"sym_stride\", \"asym_stride\"]\n","pool_strides = [\n","  [\n","    [(2, 2)], [(1, 2)]\n","  ],\n","  [\n","    [(2, 2), (2, 2), (2, 2)], [(1, 2), (1, 2), (1, 2)]\n","  ],\n","  [\n","    [(2, 2), (2, 2), (2, 2), (2, 2), (2, 2)],\n","    [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]\n","  ]\n","]\n","channels = [\n","  [\n","    [8], [16], [32], [64], [128]\n","  ],\n","  [\n","    [8, 16, 32], [8, 16, 64], [8, 32, 64], [8, 32, 128],\n","    [16, 32, 64], [16, 64, 128], [128, 128, 128]\n","  ],\n","  [\n","    [8, 16, 32, 64, 128], [8, 16, 16, 32, 64], [8, 32, 64, 64, 128,],\n","    [16, 16, 32, 64, 128], [16, 32, 32, 64, 128], [32, 32, 64, 64, 128]\n","  ]\n","]\n","\n","for i, id in enumerate(model_ids):\n","  for k, channel in enumerate(channels[i]):\n","    for j, stride in enumerate(pool_types):\n","      print(\"model id: \", id)\n","      print(\"stride: \", pool_strides[i][j])\n","      print(\"channel: \", channel)\n","      model_args = {\n","      \"channels\": channel,\n","      \"conv_kernel_sizes\": [3, 3, 3, 3, 3],\n","      #\"conv_kernel_sizes\": [3],\n","       \"conv_strides\": [1, 1, 1, 1, 1],\n","      #\"conv_strides\": [1],\n","       \"conv_paddings\": [1, 1, 1, 1, 1],\n","      #\"conv_paddings\": [1],\n","       \"pool_masks\": [True, True, True, True, True],\n","      #\"pool_masks\": [True],\n","      \"pool_kernel_sizes\": pool_strides[i][j],\n","      \"pool_strides\": pool_strides[i][j],\n","      \"linear_features\": [128, 64],\n","      \"dropout_probs\": [0.3, 0.3],\n","      }\n","      args_dict['model_id'] = id\n","      args_dict['model_args'] = model_args\n","      args_dict['experiment_params'] = {\n","        'channels': channel,\n","        'pool_kernel_sizes': pool_strides[i][j],\n","        'stride_type': stride,\n","      }\n","      args_dict['notes'] = dedent(\"\"\"\n","      varying stride and channel depth with dropout prob=0.3.\n","\n","      Other hyperparams:\n","      lr = 0.01\n","      interval: 16\n","      batch_size: 32\n","      criterion: CrossEntropyLoss\n","      \n","      \"\"\")\n","      args_dict['checkpoint_name'] = \"{}_channel{}_{}.pt\".format(\n","        id, k,stride,)\n","      train_model(**args_dict)"],"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"NVvyfWWlzOWf"},"source":[""],"execution_count":null,"outputs":[]}]}