{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bored-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_data_preparation import MfccPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "photographic-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tarfile\n",
    "import soundfile as sf\n",
    "import io\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class MfccPipeline():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.PATH = \"C:/Users/alexc/Downloads/nsynth-train.jsonwav.tar.gz\"\n",
    "\n",
    "        self.targets_list = [\n",
    "            \"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\",\n",
    "            \"mallet\", \"organ\", \"reed\", \"string\", \"synth\", \"vocal\"\n",
    "        ]\n",
    "\n",
    "    # recover wav files from tarball\n",
    "    def get_files(self, PATH=None, num_files = 100):\n",
    "        \"\"\"Sequentially pull wav files from .tar.gz file\n",
    "        :param PATH: path to compressed dataset file\n",
    "        :param num_files: number of files to read\n",
    "        :returns: 4 generators for data (wav file converted to list), sr (sample rate)\n",
    "                target name (e.g. 'guitar', 'mallet', ect.), and target index\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"getting files\")\n",
    "        if PATH is None:\n",
    "            PATH = self.PATH\n",
    "\n",
    "        # open the tar file\n",
    "        with tarfile.open(PATH, 'r:gz') as tar:\n",
    "\n",
    "            # Initialize counter to count number of files pulled.\n",
    "            index = 0\n",
    "            while index < num_files:\n",
    "                fname = tar.next()\n",
    "\n",
    "                # Break if there are no more files.\n",
    "                if fname is None:\n",
    "                    break\n",
    "\n",
    "                # Check that we're dealing with the proper format\n",
    "                if fname.name.endswith(\".wav\"):\n",
    "\n",
    "                    # Extract file\n",
    "                    wav_file = tar.extractfile(fname).read()\n",
    "\n",
    "                    # Convert bytes to a readable format\n",
    "                    data, sr = sf.read(io.BytesIO(wav_file))\n",
    "\n",
    "                    # Get target from filename\n",
    "                    target = fname.name.split('/')[2].split('_')[0]\n",
    "\n",
    "                    # yeild the 4 generators\n",
    "                    yield data, sr, target, self.targets_list.index(target)\n",
    "                    index += 1\n",
    "\n",
    "    # collect raw data into an array\n",
    "    def get_dataset(self, num_files=10):\n",
    "        \"\"\"Docstring pending\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        data_generator = self.get_files(self.PATH, num_files)\n",
    "        for i in range(num_files):\n",
    "            data.append(next(data_generator))\n",
    "        return data\n",
    "\n",
    "    # calculate mfccs\n",
    "    def get_mfccs(self, data_tuple):\n",
    "        \"\"\"Take a tuple of data (data, sr, target, target_index) and return the associated mfcc\"\"\"\n",
    "        data = np.array(data_tuple[0])\n",
    "        sr = data_tuple[1]\n",
    "        mfcc = librosa.feature.mfcc(y=data, sr=sr)\n",
    "        return mfcc\n",
    "\n",
    "    # prepare the data for input to model\n",
    "    def prepare_data(self, dataset):\n",
    "        \"\"\"Get the mfccs for each record in the dataset and the associated target values\n",
    "        \"\"\"\n",
    "\n",
    "        X = np.array([self.get_mfccs(i) for i in dataset])\n",
    "        t = to_categorical(np.array([i[3] for i in dataset]))\n",
    "\n",
    "        return X, t\n",
    "\n",
    "    def mfcc_pipeline(self, num_samples, validation_split=0.2):\n",
    "        \"\"\"Write this doc later\"\"\"\n",
    "        # get the data from tar file\n",
    "        data = self.get_dataset(num_samples)\n",
    "        X, t = self.prepare_data(data)\n",
    "\n",
    "        # split into train and validation set and return the data\n",
    "        return train_test_split(X, t, test_size=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "excellent-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MfccPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "certified-spider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PATH',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'get_dataset',\n",
       " 'get_files',\n",
       " 'get_mfccs',\n",
       " 'mfcc_pipeline',\n",
       " 'prepare_data',\n",
       " 'targets_list']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fifteen-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting files\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = pipe.mfcc_pipeline(num_samples = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "alleged-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.59742960e+01, -1.04606741e+02, -2.29081248e+02, ...,\n",
       "         -5.66862667e+02, -5.66862667e+02, -5.66862667e+02],\n",
       "        [ 1.36380829e+02,  1.44651938e+02,  1.68633632e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 4.28400310e+00,  2.15398926e+00, -7.20601795e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 3.71962189e+00,  4.57976086e+00,  5.80338805e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-1.37600947e+01, -1.34649780e+01, -7.51012292e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 5.59659274e+00,  5.11119904e+00,  1.10133784e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-1.43798420e+02, -1.92296125e+02, -3.11512839e+02, ...,\n",
       "         -5.13707716e+02, -5.15069914e+02, -5.16267922e+02],\n",
       "        [ 1.39416394e+02,  1.45631181e+02,  1.64370976e+02, ...,\n",
       "          5.82411216e+00,  3.95890164e+00,  2.33782345e+00],\n",
       "        [ 7.28854376e+01,  7.68038014e+01,  7.05111827e+01, ...,\n",
       "          5.12433760e+00,  3.43749001e+00,  2.02953214e+00],\n",
       "        ...,\n",
       "        [-1.54429815e+01, -1.66813041e+01, -1.92192533e+01, ...,\n",
       "          2.11093740e+00,  1.20440345e+00,  7.18518255e-01],\n",
       "        [ 1.21995980e+01,  1.31960557e+01,  1.58051393e+01, ...,\n",
       "          3.54027642e+00,  2.26994938e+00,  1.34719702e+00],\n",
       "        [-2.87882939e+00, -2.33287752e+00, -5.30537159e+00, ...,\n",
       "          4.69918456e+00,  3.13374053e+00,  1.85601209e+00]],\n",
       "\n",
       "       [[-3.84494003e+02, -4.05436492e+02, -4.89249377e+02, ...,\n",
       "         -5.82727899e+02, -5.82727899e+02, -5.82727899e+02],\n",
       "        [ 2.39552827e+02,  2.17096162e+02,  1.12898226e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 1.45789685e+02,  1.38249786e+02,  6.88866578e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 8.00344149e-01, -1.36047102e+00, -6.10147599e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-1.59773317e+00, -6.62270990e+00, -8.94900927e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-7.56539577e+00, -1.02164942e+01, -3.65937927e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.06010318e+02, -1.59978653e+02, -4.08169942e+02, ...,\n",
       "         -4.91278357e+02, -4.91278357e+02, -4.91278357e+02],\n",
       "        [ 1.75093014e+02,  1.68579328e+02,  3.13025568e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-6.91638259e+01, -6.54438899e+01, -2.41666486e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-9.65386082e+00, -1.22835494e+01, -3.15715250e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-1.58221755e+01, -1.52262668e+01, -2.74871992e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 8.59753746e+00,  1.38853335e+01,  5.90529324e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-1.19790943e+02, -1.77799059e+02, -3.83553641e+02, ...,\n",
       "         -5.29999684e+02, -5.29999684e+02, -5.29999684e+02],\n",
       "        [ 1.12860208e+02,  1.10439464e+02,  7.90573385e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-6.76322621e+00, -9.57340006e+00, -4.71885959e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 1.71878050e-02, -7.53965576e-01, -9.82917762e-01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 3.77261471e+01,  4.19173030e+01,  5.13689282e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-1.31297318e+01, -9.31541724e+00,  9.99922075e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-1.45919262e+02, -1.73897005e+02, -2.99104207e+02, ...,\n",
       "         -5.77607080e+02, -5.77607080e+02, -5.77607080e+02],\n",
       "        [ 2.84384155e+02,  2.88703165e+02,  2.69365382e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-5.98464374e+01, -3.60581568e+01,  6.35734752e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-6.40128998e+00, -6.70105577e+00, -8.64110923e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-6.18951470e+00, -8.38210388e+00, -8.73568130e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-6.75182047e+00, -7.19748426e+00, -8.84410772e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-holder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_analysis",
   "language": "python",
   "name": "music_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
